{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     57619\n",
      "1     25392\n",
      "-1    16902\n",
      "Name: 情感倾向, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_labled_path = './data/nCoV_100k_train.labled.csv'\n",
    "test_path='./data/nCov_10k_test.csv'\n",
    "df = pd.read_csv(train_labled_path, encoding='utf-8', usecols=[3,6])\n",
    "df2 = pd.read_csv(test_path, encoding='utf-8', usecols=[0,3])\n",
    "df = df[df['情感倾向'].isin(['0','-1','1'])]\n",
    "print(df['情感倾向'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 删除停用词+中文分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def stopwords_list(d):\n",
    "    with open('./data/'+d,'rb') as f:\n",
    "        lines = f.readlines()\n",
    "        result = [i.decode().strip('\\n') for i in lines]\n",
    "    return result\n",
    "\n",
    "stopwords = stopwords_list('hit_stopwords.txt')\n",
    "stopwords.extend(stopwords_list('cn_stopwords.txt'))\n",
    "stopwords.extend(stopwords_list('baidu_stopwords.txt'))\n",
    "stopwords.extend(stopwords_list('scu_stopwords.txt'))\n",
    "def remove_punctuation(line):\n",
    "    line = str(line)\n",
    "    if line.strip()=='':\n",
    "        return ''\n",
    "    rule = re.compile(u\"[^a-zA-Z0-9\\u4E00-\\u9FA5]\")\n",
    "    line = rule.sub('',line)\n",
    "    return line\n",
    "\n",
    "df['clean_comment']=df['微博中文内容'].apply(remove_punctuation)\n",
    "df2['clean_comment']=df2['微博中文内容'].apply(remove_punctuation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\WWWWWW~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.080 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>微博中文内容</th>\n",
       "      <th>情感倾向</th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>cut_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>写在年末冬初孩子流感的第五天，我们仍然没有忘记热情拥抱这2020年的第一天。带着一丝迷信，早...</td>\n",
       "      <td>0</td>\n",
       "      <td>写在年末冬初孩子流感的第五天我们仍然没有忘记热情拥抱这2020年的第一天带着一丝迷信早晨给孩...</td>\n",
       "      <td>写 年末 冬初 孩子 流感 第五天 忘记 热情 拥抱 2020 年 第一天 带 一丝 迷信 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>开年大模型…累到以为自己发烧了腰疼膝盖疼腿疼胳膊疼脖子疼#Luna的Krystallife#?</td>\n",
       "      <td>-1</td>\n",
       "      <td>开年大模型累到以为自己发烧了腰疼膝盖疼腿疼胳膊疼脖子疼Luna的Krystallife</td>\n",
       "      <td>开年 模型 累到 发烧 腰疼 膝盖 疼 腿疼 胳膊 疼 脖子 疼 Luna Krystallife</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>邱晨这就是我爹，爹，发烧快好，毕竟美好的假期拿来养病不太好，假期还是要好好享受快乐，爹，新...</td>\n",
       "      <td>1</td>\n",
       "      <td>邱晨这就是我爹爹发烧快好毕竟美好的假期拿来养病不太好假期还是要好好享受快乐爹新年快乐发烧好了...</td>\n",
       "      <td>邱晨 爹爹 发烧 快 美好 假期 拿来 养病 不太好 假期 好好 享受 快乐 爹 新年快乐 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>新年的第一天感冒又发烧的也太衰了但是我要想着明天一定会好的?</td>\n",
       "      <td>1</td>\n",
       "      <td>新年的第一天感冒又发烧的也太衰了但是我要想着明天一定会好的</td>\n",
       "      <td>新年 第一天 感冒 发烧 太衰 我要 想着 明天</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>问：我们意念里有坏的想法了，天神就会给记下来，那如果有好的想法也会被记下来吗？答：那当然了。...</td>\n",
       "      <td>1</td>\n",
       "      <td>问我们意念里有坏的想法了天神就会给记下来那如果有好的想法也会被记下来吗答那当然了有坏的想法天...</td>\n",
       "      <td>问 意念 里 坏 想法 天神 记下来 想法 记下来 答 坏 想法 天神 会记 头上 三尺 神...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>发高烧反反复复，眼睛都快睁不开了。今天室友带我去看，还在发烧中建议我输液，我拒绝了。给我打针...</td>\n",
       "      <td>-1</td>\n",
       "      <td>发高烧反反复复眼睛都快睁不开了今天室友带我去看还在发烧中建议我输液我拒绝了给我打针你今天吃东...</td>\n",
       "      <td>发高烧 反反复复 眼睛 快 睁不开 室友 带我去 发烧 中 建议 输液 拒绝 打针 吃 东西...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>明天考试今天发烧跨年给我跨坏了？？2兰州·兰州交通大学?</td>\n",
       "      <td>-1</td>\n",
       "      <td>明天考试今天发烧跨年给我跨坏了2兰州兰州交通大学</td>\n",
       "      <td>明天 考试 发烧 跨年 跨坏 兰州 兰州 交通 大学</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>#元旦快乐##枇杷手法小结#每个娃都是有故事的娃。每个大人也是有故事的大人。小枇杷有茶有手法...</td>\n",
       "      <td>0</td>\n",
       "      <td>元旦快乐枇杷手法小结每个娃都是有故事的娃每个大人也是有故事的大人小枇杷有茶有手法静待每个有需...</td>\n",
       "      <td>元旦 快乐 枇杷 手法 小结 娃 故事 娃 大人 故事 大人 枇杷 茶 手法 静待 需求 大...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>我真的服了xkh昨天vv去和她说自己不舒服，描述了症状她说啊你这不是感冒没有发烧没事的晚上一...</td>\n",
       "      <td>-1</td>\n",
       "      <td>我真的服了xkh昨天vv去和她说自己不舒服描述了症状她说啊你这不是感冒没有发烧没事的晚上一回...</td>\n",
       "      <td>真的 服 xkh 昨天 vv 说 舒服 描述 症状 说 感冒 发烧 没事 晚上 一回 寝 发...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>新年第一天，为自己鼓掌??????发烧了也要来看线下演出！因为热爱，所以才会克服困难线上演出...</td>\n",
       "      <td>1</td>\n",
       "      <td>新年第一天为自己鼓掌发烧了也要来看线下演出因为热爱所以才会克服困难线上演出太炸了爱呼兰爱赵晓...</td>\n",
       "      <td>新年 第一天 鼓掌 发烧 线下 演出 热爱 克服困难 线上 演出 太炸 爱 呼兰 爱 赵晓卉...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              微博中文内容 情感倾向  \\\n",
       "0  写在年末冬初孩子流感的第五天，我们仍然没有忘记热情拥抱这2020年的第一天。带着一丝迷信，早...    0   \n",
       "1    开年大模型…累到以为自己发烧了腰疼膝盖疼腿疼胳膊疼脖子疼#Luna的Krystallife#?   -1   \n",
       "2  邱晨这就是我爹，爹，发烧快好，毕竟美好的假期拿来养病不太好，假期还是要好好享受快乐，爹，新...    1   \n",
       "3                     新年的第一天感冒又发烧的也太衰了但是我要想着明天一定会好的?    1   \n",
       "4  问：我们意念里有坏的想法了，天神就会给记下来，那如果有好的想法也会被记下来吗？答：那当然了。...    1   \n",
       "5  发高烧反反复复，眼睛都快睁不开了。今天室友带我去看，还在发烧中建议我输液，我拒绝了。给我打针...   -1   \n",
       "6                       明天考试今天发烧跨年给我跨坏了？？2兰州·兰州交通大学?   -1   \n",
       "7  #元旦快乐##枇杷手法小结#每个娃都是有故事的娃。每个大人也是有故事的大人。小枇杷有茶有手法...    0   \n",
       "8  我真的服了xkh昨天vv去和她说自己不舒服，描述了症状她说啊你这不是感冒没有发烧没事的晚上一...   -1   \n",
       "9  新年第一天，为自己鼓掌??????发烧了也要来看线下演出！因为热爱，所以才会克服困难线上演出...    1   \n",
       "\n",
       "                                       clean_comment  \\\n",
       "0  写在年末冬初孩子流感的第五天我们仍然没有忘记热情拥抱这2020年的第一天带着一丝迷信早晨给孩...   \n",
       "1        开年大模型累到以为自己发烧了腰疼膝盖疼腿疼胳膊疼脖子疼Luna的Krystallife   \n",
       "2  邱晨这就是我爹爹发烧快好毕竟美好的假期拿来养病不太好假期还是要好好享受快乐爹新年快乐发烧好了...   \n",
       "3                      新年的第一天感冒又发烧的也太衰了但是我要想着明天一定会好的   \n",
       "4  问我们意念里有坏的想法了天神就会给记下来那如果有好的想法也会被记下来吗答那当然了有坏的想法天...   \n",
       "5  发高烧反反复复眼睛都快睁不开了今天室友带我去看还在发烧中建议我输液我拒绝了给我打针你今天吃东...   \n",
       "6                           明天考试今天发烧跨年给我跨坏了2兰州兰州交通大学   \n",
       "7  元旦快乐枇杷手法小结每个娃都是有故事的娃每个大人也是有故事的大人小枇杷有茶有手法静待每个有需...   \n",
       "8  我真的服了xkh昨天vv去和她说自己不舒服描述了症状她说啊你这不是感冒没有发烧没事的晚上一回...   \n",
       "9  新年第一天为自己鼓掌发烧了也要来看线下演出因为热爱所以才会克服困难线上演出太炸了爱呼兰爱赵晓...   \n",
       "\n",
       "                                         cut_comment  \n",
       "0  写 年末 冬初 孩子 流感 第五天 忘记 热情 拥抱 2020 年 第一天 带 一丝 迷信 ...  \n",
       "1  开年 模型 累到 发烧 腰疼 膝盖 疼 腿疼 胳膊 疼 脖子 疼 Luna Krystallife  \n",
       "2  邱晨 爹爹 发烧 快 美好 假期 拿来 养病 不太好 假期 好好 享受 快乐 爹 新年快乐 ...  \n",
       "3                           新年 第一天 感冒 发烧 太衰 我要 想着 明天  \n",
       "4  问 意念 里 坏 想法 天神 记下来 想法 记下来 答 坏 想法 天神 会记 头上 三尺 神...  \n",
       "5  发高烧 反反复复 眼睛 快 睁不开 室友 带我去 发烧 中 建议 输液 拒绝 打针 吃 东西...  \n",
       "6                         明天 考试 发烧 跨年 跨坏 兰州 兰州 交通 大学  \n",
       "7  元旦 快乐 枇杷 手法 小结 娃 故事 娃 大人 故事 大人 枇杷 茶 手法 静待 需求 大...  \n",
       "8  真的 服 xkh 昨天 vv 说 舒服 描述 症状 说 感冒 发烧 没事 晚上 一回 寝 发...  \n",
       "9  新年 第一天 鼓掌 发烧 线下 演出 热爱 克服困难 线上 演出 太炸 爱 呼兰 爱 赵晓卉...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba as jb\n",
    "\n",
    "df['cut_comment'] = df['clean_comment'].apply(lambda x: \" \".join([w for w in list(jb.cut(x)) if w not in stopwords]))\n",
    "df2['cut_comment'] = df2['clean_comment'].apply(lambda x: \" \".join([w for w in list(jb.cut(x)) if w not in stopwords]))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99913, 4)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "MAX_NB_WORDS = 90000\n",
    "MAX_SEQUENCE_LENGTH = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98913, 60) (98913, 3)\n",
      "(1000, 60) (1000, 3)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(df['cut_comment'].values)\n",
    "\n",
    "X = tokenizer.texts_to_sequences(df['cut_comment'].values)\n",
    "#填充X,让X的各个列的长度统一\n",
    "X = pad_sequences(X, MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "#多类标签的onehot展开\n",
    "Y = pd.get_dummies(df['情感倾向']).values\n",
    "\n",
    "\n",
    "#结果集\n",
    "X_ans = tokenizer.texts_to_sequences(df2['cut_comment'].values)\n",
    "#填充X,让X的各个列的长度统一\n",
    "X_ans = pad_sequences(X_ans, MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "\n",
    "#拆分训练集和测试集\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.01, random_state = 42)\n",
    "\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89999\n",
      "[[    0     0     0 ...     6     5     4]\n",
      " [    0     0     0 ...  1356 46196 79433]\n",
      " [    0     0     0 ...  6621  6621 30660]\n",
      " ...\n",
      " [    0     0     0 ...     7     9   780]\n",
      " [    0     0     0 ... 46063   581  3328]\n",
      " [    0     0     0 ...   538  7078    19]]\n"
     ]
    }
   ],
   "source": [
    "print(X.max())\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import SpatialDropout1D,Bidirectional\n",
    "from keras.callbacks import EarlyStopping\n",
    "EMBEDDING_DIM = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\contest\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 89021 samples, validate on 9892 samples\n",
      "Epoch 1/20\n",
      "89021/89021 [==============================] - 1059s 12ms/step - loss: 0.4202 - accuracy: 0.8049 - val_loss: 0.3955 - val_accuracy: 0.8145\n",
      "Epoch 2/20\n",
      "89021/89021 [==============================] - 1090s 12ms/step - loss: 0.3079 - accuracy: 0.8678 - val_loss: 0.4069 - val_accuracy: 0.8195\n",
      "Epoch 3/20\n",
      "89021/89021 [==============================] - 1139s 13ms/step - loss: 0.2140 - accuracy: 0.9129 - val_loss: 0.4970 - val_accuracy: 0.8029\n",
      "Epoch 4/20\n",
      "89021/89021 [==============================] - 1075s 12ms/step - loss: 0.1533 - accuracy: 0.9384 - val_loss: 0.5978 - val_accuracy: 0.8027\n"
     ]
    }
   ],
   "source": [
    "#submit4-5 sigmoid softmax\n",
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1])) # 嵌入层将维数降到128\n",
    "model.add(Bidirectional(LSTM(64))) # 双向LSTM层\n",
    "model.add(Dropout(0.4)) # 随机失活\n",
    "model.add(Dense(3,activation='softmax')) # 稠密层 将情感分类0或1\n",
    "model.compile('adam','binary_crossentropy',metrics=['accuracy']) # 二元交叉熵\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 64\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,\n",
    "                    callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''#submit2-3 调整了dropout\n",
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(50, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(3, activation='softmax'))#预测结果为3类\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 64\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.3,\n",
    "                    callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n",
    "''''''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X_ans)\n",
    "pred_label = pred.argmax(axis=1) - 1\n",
    "#for i in df2['微博中文内容']:\n",
    "    #pred_label.append(predict(i))\n",
    "    \n",
    "#print(\"预测的分类标签为:\",pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict={\"测试数据id\":df2['微博id'].values.tolist(),'情感极性':pred_label.tolist()}\n",
    "#output_list = [df2['微博id'].values.tolist(),pred_label.tolist()]\n",
    "output = pd.DataFrame(dict)\n",
    "output.to_csv(\"./submit5.csv\",sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(output_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

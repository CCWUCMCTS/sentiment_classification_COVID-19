{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_labled_path = './data/nCoV_100k_train.labled.csv'\n",
    "test_path='./data/nCov_10k_test.csv'\n",
    "df = pd.read_csv(train_labled_path, encoding='utf-8', usecols=[3,6])\n",
    "df2 = pd.read_csv(test_path, encoding='utf-8', usecols=[0,3])\n",
    "df = df[df['情感倾向'].isin(['0','-1','1'])]\n",
    "print(df['情感倾向'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 中文分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "df['微博中文内容']=df['微博中文内容'].map(str)\n",
    "df['cuted']=df['微博中文内容'].map(lambda x:' '.join(jieba.cut(x)))\n",
    "df2['微博中文内容']=df2['微博中文内容'].map(str)\n",
    "df2['cuted']=df2['微博中文内容'].map(lambda x:' '.join(jieba.cut(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['cuted'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入和输出\n",
    "X = df['cuted']\n",
    "y = df['情感倾向']\n",
    "x_ans = df2['cuted']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.01, random_state=0)\n",
    "\n",
    "# 查看训练集\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# 变换器\n",
    "vect = CountVectorizer()\n",
    "\n",
    "vect.fit(X_train)\n",
    "\n",
    "# 词表数量\n",
    "print(len(vect.vocabulary_))\n",
    "# 打印词表\n",
    "#print(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words_matrix = pd.DataFrame(vect.transform(X).toarray(),columns=vect.get_feature_names())\n",
    "\n",
    "#words_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# 交叉验证评估模型\n",
    "scores = cross_val_score(LogisticRegression(),\n",
    "                         vect.transform(X_train), y_train, cv=5)\n",
    "print('平均交叉验证准确率：{:.3f}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 去除停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords_list(d):\n",
    "    with open('./data/'+d,'rb') as f:\n",
    "        lines = f.readlines()\n",
    "        result = [i.decode().strip('\\n') for i in lines]\n",
    "    return result\n",
    "\n",
    "stopwords = stopwords_list('hit_stopwords.txt')\n",
    "stopwords.extend(stopwords_list('cn_stopwords.txt'))\n",
    "stopwords.extend(stopwords_list('baidu_stopwords.txt'))\n",
    "stopwords.extend(stopwords_list('scu_stopwords.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(max_df=0.8, min_df=3, stop_words=stopwords,\n",
    "                       token_pattern=u'(?u)\\\\b[^\\\\d\\\\W]\\\\w+\\\\b')\n",
    "\n",
    "vect.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#words_matrix = pd.DataFrame(vect.transform(X_train).toarray(),columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "lr=LogisticRegression()\n",
    "lr.fit(vect.transform(X_train), y_train)\n",
    "\n",
    "print('测试集准确率：{:.3f}'.format(lr.score(vect.transform(X_test), y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用tf-idf缩放数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe = make_pipeline(TfidfVectorizer(min_df=3), LogisticRegression())\n",
    "pipe.fit(X_train, y_train)\n",
    "scores = cross_val_score(pipe, X_train, y_train, cv=5)\n",
    "print('平均交叉验证准确率：{:.3f}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = pipe.named_steps['tfidfvectorizer']\n",
    "# 找到每个特征中最大值\n",
    "max_value = vectorizer.transform(X_train).max(axis=0).toarray().ravel()\n",
    "sorted_by_tfidf = max_value.argsort()\n",
    "# 获取特征名称\n",
    "feature_names = np.array(vectorizer.get_feature_names())\n",
    "\n",
    "print(\"tfidf较低的特征：\\n{}\".format(feature_names[sorted_by_tfidf[:20]]))\n",
    "print()\n",
    "print(\"tfidf较高的特征：\\n{}\".format( feature_names[sorted_by_tfidf[-20:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# 预测值\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print('测试集准确率：{:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "print('测试集准确率：{:.3f}'.format(pipe.score(X_test, y_test)))\n",
    "\n",
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(pd.value_counts(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-52a01e269386>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_ans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_ans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pipe' is not defined"
     ]
    }
   ],
   "source": [
    "y_ans = pipe.predict(x_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ans = pipe.predict(x_ans)\n",
    "dict={\"测试数据id\":df2['微博id'].values.tolist(),'情感极性':y_ans.tolist()}\n",
    "output_list = [df2['微博id'].values.tolist(),y_ans.tolist()]\n",
    "output = pd.DataFrame(dict)\n",
    "output.to_csv(\"./submit1.csv\",sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(output_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
